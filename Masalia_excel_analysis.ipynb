{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install pandas\n",
        "!pip install os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jXmWsUTdQC_m",
        "outputId": "b1f4f3ce-ff0c-4778-d1d8-cc30d176e500"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.27.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "collapsed": true,
        "id": "6r-coOQWQ_15",
        "outputId": "f628e065-673b-4e95-df27-6c8a2a165b5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.27.8) (4.12.2)\n",
            "Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-0.27.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "035b9bc40aca45a4974b20a397804a1b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ8pqUHNOsl5",
        "outputId": "fbccc6b1-ce81-4bc3-f397-ec7622ece508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the percentage of land classified as hill slope and plain area for UID 12_307609, we can refer to the \"terrain\" sheet.\n",
            "\n",
            "Based on the columns:\n",
            "- % of area hill_slope\n",
            "- % of area plain_area\n",
            "\n",
            "You would typically retrieve the values corresponding to UID 12_307609 from that sheet.\n",
            "\n",
            "If you have access to the data, please look for UID 12_307609 in the \"terrain\" sheet and locate the required percentages. If you want me to summarize or calculate additional insights based on those values, please provide the specific numbers.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Set OpenAI API key\n",
        "api_key = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Path to the uploaded Excel file\n",
        "file_path = \"/content/Masalia_data.xlsx\"\n",
        "\n",
        "# Load all sheets from the Excel file\n",
        "def load_excel_sheets(file_path):\n",
        "    \"\"\"\n",
        "    Reads all sheets from an Excel file into a dictionary of DataFrames.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = pd.read_excel(file_path, sheet_name=None)  # Load all sheets into a dictionary\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Excel file: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Store the data in a dictionary\n",
        "excel_data = load_excel_sheets(file_path)\n",
        "\n",
        "# Prepare data summary\n",
        "def summarize_excel_data(data):\n",
        "    \"\"\"\n",
        "    Summarizes the content of all sheets in the Excel file.\n",
        "    \"\"\"\n",
        "    summaries = []\n",
        "    for sheet_name, df in data.items():\n",
        "        summaries.append(\n",
        "            f\"Sheet: {sheet_name}\\n\"\n",
        "            f\"Number of rows: {df.shape[0]}, Number of columns: {df.shape[1]}\\n\"\n",
        "            f\"Columns: {', '.join(df.columns)}\\n\"\n",
        "        )\n",
        "    return \"\\n\".join(summaries)\n",
        "\n",
        "data_summary = summarize_excel_data(excel_data)\n",
        "\n",
        "# Generate a context for OpenAI queries\n",
        "combined_context = (\n",
        "    f\"Data Summary:\\n{data_summary}\\n\\n\"\n",
        "    \"The data from the Excel sheets is ready for analysis. You can now ask questions \"\n",
        "    \"based on this data, and I will process your queries accordingly.\"\n",
        ")\n",
        "\n",
        "# Example function to query the model\n",
        "def query_model(query, context):\n",
        "    \"\"\"\n",
        "    Sends a query to OpenAI with the provided context.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a data analysis assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{context}\\n\\n{query}\"}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"Error querying the model: {e}\"\n",
        "\n",
        "# Example query\n",
        "example_query = \"What are the %age of land hill slope and plain area for the UID 12_307609?\"\n",
        "response = query_model(example_query, combined_context)\n",
        "\n",
        "# Print the response\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Set up OpenAI API key\n",
        "api_key = \"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\"\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = \"/content/Masalia_data.xlsx\"  # Path to your Excel file\n",
        "uid_to_fetch = \"12_307609\"  # UID to locate in the sheet\n",
        "\n",
        "# Step 1: Extract Data from Excel\n",
        "terrain_sheet = pd.read_excel(file_path, sheet_name=\"terrain\")\n",
        "\n",
        "# Filter the row for the specific UID\n",
        "row_data = terrain_sheet[terrain_sheet[\"UID\"] == uid_to_fetch]\n",
        "\n",
        "if not row_data.empty:\n",
        "    # Fetch the required percentages\n",
        "    hill_slope = row_data[\"% of area hill_slope\"].values[0]\n",
        "    plain_area = row_data[\"% of area plain_area\"].values[0]\n",
        "\n",
        "    # Calculate the total percentage\n",
        "    total_percentage = hill_slope + plain_area\n",
        "\n",
        "    # Step 2: Construct Prompt for LLM\n",
        "    prompt = (\n",
        "        f\"The land data for UID {uid_to_fetch} has been analyzed. Here are the details:\\n\"\n",
        "        f\"- Percentage of hill slope area: {hill_slope}%\\n\"\n",
        "        f\"- Percentage of plain area: {plain_area}%\\n\"\n",
        "        f\"- Total percentage of land use (hill slope + plain area): {total_percentage}%\\n\\n\"\n",
        "        \"Analyze this data and provide insights on whether this represents a good condition for land usage. \"\n",
        "        \"Explain your reasoning based on general land use and terrain analysis principles.\"\n",
        "    )\n",
        "\n",
        "    # Step 3: Query the LLM\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a land-use and terrain analysis expert.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=500,\n",
        "        )\n",
        "\n",
        "        # Step 4: Output the Model's Analysis\n",
        "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying the model: {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"No data found for UID {uid_to_fetch} in the 'terrain' sheet.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He27z-qMQN4v",
        "outputId": "35d5718d-e61f-4306-8185-f4ac04bcf045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided data, the land represented by UID 12_307609 appears to be primarily composed of plain area (60.35%) with a smaller portion being hill slope area (4.60%). The total land use is approximately 65.0%, which implies there are around 35% of the land that could be water bodies, forests, or other non-user specific areas. \n",
            "\n",
            "Generally, plain areas tend to be more productive for various land uses, including agriculture, settlement, infrastructure development and so on. This is mainly due to their even terrain, which is often easier for machinery to navigate, and better suited for the construction of buildings. That said, the usability of the plain area largely depends on the soil type, the availability of water resources, whether this flat terrain is prone to flooding, and its proximity to existing infrastructure.\n",
            "\n",
            "On the other hand, hill slope areas can present challenges for traditional land uses due to their gradient. The steeper the slope, the more challenging it can be to effectively use for many purposes, particularly agriculture and construction. Land on a slope can be more prone to soil erosion and would require additional inputs like terracing for cultivation. That said, slopes can also offer opportunities. For example, they may be well suited for certain types of agriculture (like vineyards or orchards), or for recreational uses.\n",
            "\n",
            "The decision on whether this represents good conditions for land usage depends heavily on the intended use of the land. For example, if the intended use is agricultural, then soil quality, climate, and water availability would need to be considered. If the land is intended for construction, then factors such as proximity to infrastructure, susceptibility to natural disasters (e.g. flooding or landslides in hilly areas) and the cost of construction on the terrain would need to addressed. \n",
            "\n",
            "In conclusion, this data suggests that location UID 12_307609 may provide good conditions for certain types of land usage, but a more detailed analysis would be required to make an accurate assessment. This would need to include an evaluation of other factors such as soil quality, climate, water availability, proximity to infrastructure, and intended land use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas shapely matplotlib\n",
        "!pip install openai  # For using the LLM\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37kTKXDzP95v",
        "outputId": "f86155f5-9eca-4ecb-89c3-6a2bd1df360a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hwXMgrLWI2A",
        "outputId": "e53a9ebe-9ba6-40fe-c018-d6999cf19e01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import geopandas as gpd\n",
        "\n",
        "def extract_zip_and_load_shapefile(zip_path, shapefile_name=None):\n",
        "    \"\"\"\n",
        "    Extracts a ZIP archive and loads the specified shapefile using GeoPandas.\n",
        "\n",
        "    Parameters:\n",
        "        zip_path (str): Path to the ZIP file containing shapefiles.\n",
        "        shapefile_name (str): Name of the `.shp` file to load (optional). If None, it loads the first `.shp` found.\n",
        "\n",
        "    Returns:\n",
        "        geopandas.GeoDataFrame: The loaded GeoDataFrame from the shapefile.\n",
        "    \"\"\"\n",
        "    # Create a temporary directory for extraction\n",
        "    extract_dir = \"temp_shapefile\"\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    # Extract the ZIP file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "    # Find the shapefile (.shp) in the extracted contents\n",
        "    shapefiles = [file for file in os.listdir(extract_dir) if file.endswith(\".shp\")]\n",
        "\n",
        "    if not shapefiles:\n",
        "        raise FileNotFoundError(\"No shapefile (.shp) found in the ZIP archive.\")\n",
        "\n",
        "    # If a specific shapefile is not specified, load the first one found\n",
        "    shapefile_to_load = shapefile_name if shapefile_name else shapefiles[0]\n",
        "\n",
        "    # Construct the full path to the shapefile\n",
        "    shapefile_path = os.path.join(extract_dir, shapefile_to_load)\n",
        "\n",
        "    # Load the shapefile with GeoPandas\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    # Clean up extracted files (optional: remove temp folder after loading)\n",
        "    # import shutil\n",
        "    # shutil.rmtree(extract_dir)\n",
        "\n",
        "    return gdf\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_path_villages = \"/content/anugul_anugul.zip\"\n",
        "zip_path_microwatersheds = \"/content/angul_waterbodies.zip\"\n",
        "\n",
        "# Load the shapefiles\n",
        "villages = extract_zip_and_load_shapefile(zip_path_villages)\n",
        "microwatersheds = extract_zip_and_load_shapefile(zip_path_microwatersheds)\n",
        "\n",
        "# Perform intersection\n",
        "intersection = gpd.overlay(villages, microwatersheds, how='intersection')\n",
        "\n",
        "# Save the result to a new shapefile or GeoJSON (optional)\n",
        "output_path = \"intersection_result.shp\"\n",
        "intersection.to_file(output_path)\n",
        "\n",
        "# Display the first few rows of the resulting GeoDataFrame\n",
        "print(intersection.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM6nNBfrV9MO",
        "outputId": "df79fda4-62d1-4c74-8439-6d6951872cf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty GeoDataFrame\n",
            "Columns: [ADI_2001, ADI_2011, ADI_2019, ASSET_2001, ASSET_2011, ASSET_2019, BF_2001, BF_2011, BF_2019, FC_2001, FC_2011, FC_2019, F_ILL, F_LIT, F_SC, F_ST, MSW_2001, MSW_2011, MSW_2019, M_ILL, M_LIT, M_SC, M_ST, No_HH, P_ILL, P_LIT, P_SC, P_ST, TOT_F, TOT_M, TOT_P, block_cen, dist_cen, district, state, state_cen, tehsil, vill_ID, vill_name, k_p_perc, area_m2, k_r_z_perc, total_pix, k_r_z, k_r_p_perc, k_p, k_r_p, geometry]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ChatCompletion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uol06g2QWuKW",
        "outputId": "42bbba93-78ba-4d40-b0a7-7cddaec6e9bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ChatCompletion (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ChatCompletion\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "collapsed": true,
        "id": "ta3gxKypW-31",
        "outputId": "d73a3779-a0de-4a47-f6b0-52b66fe9690a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "714cd290d2ed4f8eaa324ae9ea9eeee9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import geopandas as gpd\n",
        "from openai import ChatCompletion\n",
        "\n",
        "# Set your OpenAI API key\n",
        "api_key = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "client = ChatCompletion()\n",
        "\n",
        "def extract_zip_and_load_shapefile(zip_path, shapefile_name=None):\n",
        "    \"\"\"\n",
        "    Extracts a ZIP archive and loads the specified shapefile using GeoPandas.\n",
        "\n",
        "    Parameters:\n",
        "        zip_path (str): Path to the ZIP file containing shapefiles.\n",
        "        shapefile_name (str): Name of the `.shp` file to load (optional). If None, it loads the first `.shp` found.\n",
        "\n",
        "    Returns:\n",
        "        geopandas.GeoDataFrame: The loaded GeoDataFrame from the shapefile.\n",
        "    \"\"\"\n",
        "    extract_dir = \"temp_shapefile\"\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "    shapefiles = [file for file in os.listdir(extract_dir) if file.endswith(\".shp\")]\n",
        "\n",
        "    if not shapefiles:\n",
        "        raise FileNotFoundError(\"No shapefile (.shp) found in the ZIP archive.\")\n",
        "\n",
        "    shapefile_to_load = shapefile_name if shapefile_name else shapefiles[0]\n",
        "    shapefile_path = os.path.join(extract_dir, shapefile_to_load)\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    return gdf\n",
        "\n",
        "def prepare_intersection_summary(intersection_gdf):\n",
        "    \"\"\"\n",
        "    Summarizes the key attributes of the intersection results.\n",
        "\n",
        "    Parameters:\n",
        "        intersection_gdf (GeoDataFrame): The GeoDataFrame resulting from the intersection.\n",
        "\n",
        "    Returns:\n",
        "        str: A summary of key attributes.\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    for idx, row in intersection_gdf.iterrows():\n",
        "        summary.append(f\"ID: {row.get('id', 'N/A')}, Area: {row.geometry.area:.2f}, Other Info: {dict(row)}\")\n",
        "        if len(summary) >= 10:  # Limit to the first 10 entries\n",
        "            break\n",
        "    return \"\\n\".join(summary)\n",
        "\n",
        "# Paths to ZIP files\n",
        "zip_path_villages = \"/content/anugul_anugul.zip\"\n",
        "zip_path_microwatersheds = \"/content/angul_waterbodies.zip\"\n",
        "\n",
        "# Load shapefiles\n",
        "villages = extract_zip_and_load_shapefile(zip_path_villages)\n",
        "microwatersheds = extract_zip_and_load_shapefile(zip_path_microwatersheds)\n",
        "\n",
        "# Perform intersection\n",
        "intersection = gpd.overlay(villages, microwatersheds, how='intersection')\n",
        "\n",
        "# Prepare a summary of the intersection results\n",
        "intersection_summary = prepare_intersection_summary(intersection)\n",
        "\n",
        "# Context and Prompt for the LLM\n",
        "context = (\n",
        "    \"I have performed a spatial analysis where village polygons were intersected with microwatershed polygons.\\n\"\n",
        "    f\"The following is a summary of the intersection results:\\n{intersection_summary}\\n\\n\"\n",
        "    \"Please analyze these results and provide insights on:\\n\"\n",
        "    \"- The distribution of land across different villages and microwatersheds.\\n\"\n",
        "    \"- Recommendations for land management based on the areas and other attributes.\\n\"\n",
        "    \"- Any potential issues or notable observations from the data.\"\n",
        ")\n",
        "\n",
        "# Query the LLM\n",
        "response = client.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert in GIS and spatial data analysis.\"},\n",
        "        {\"role\": \"user\", \"content\": context},\n",
        "    ],\n",
        "    max_tokens=1000,\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "# Print the LLM response\n",
        "print(response.choices[0].message[\"content\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "73MBU4NpWkMg",
        "outputId": "b07dcfcb-dcd7-40c3-8bd3-504f93fed908"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7ec58d425646>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Query the LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m response = client.create(\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__prepare_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36m__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_TIMEOUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         requestor = api_requestor.APIRequestor(\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mapi_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    136\u001b[0m     ):\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_base\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         self.api_type = (\n\u001b[1;32m    140\u001b[0m             \u001b[0mApiType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/util.py\u001b[0m in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise openai.error.AuthenticationError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;34m\"No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         )\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "api_key = \"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\"\n",
        "\n",
        "\n",
        "# Paths to your shapefiles\n",
        "village_shapefile_path = \"/content/anugul_anugul.shp\"\n",
        "microwatershed_shapefile_path = \"/content/angul_waterbodies.shp\"\n",
        "\n",
        "# Load shapefiles using GeoPandas\n",
        "villages = gpd.read_file(village_shapefile_path)\n",
        "microwatersheds = gpd.read_file(microwatershed_shapefile_path)\n",
        "\n",
        "# Ensure both layers use the same CRS\n",
        "villages = villages.to_crs(microwatersheds.crs)\n",
        "\n",
        "# Perform spatial intersection\n",
        "intersection = gpd.overlay(villages, microwatersheds, how=\"intersection\")\n",
        "\n",
        "# Save the result to a GeoJSON (optional, for visualization or debugging)\n",
        "output_path = \"/path/to/intersection_result.geojson\"\n",
        "intersection.to_file(output_path, driver=\"GeoJSON\")\n",
        "\n",
        "# Prepare data summary for LLM\n",
        "data_summary = intersection[[\"village_name\", \"watershed_id\", \"geometry\"]].head().to_json()\n",
        "\n",
        "# Prepare prompt for LLM\n",
        "prompt = (\n",
        "    f\"The result of intersecting village boundaries with microwatersheds is as follows:\\n\\n\"\n",
        "    f\"{data_summary}\\n\\n\"\n",
        "    \"Analyze this data and provide insights, such as:\\n\"\n",
        "    \"- How many villages are impacted by each watershed?\\n\"\n",
        "    \"- What are the potential implications for resource management?\\n\"\n",
        "    \"- Are there any spatial patterns worth noting?\"\n",
        ")\n",
        "\n",
        "# Query the LLM\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a geospatial data analysis expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    # Print the model's response\n",
        "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error querying the model: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "rfCJ9-KrSOMT",
        "outputId": "321c5ee5-4b7b-4d36-89c1-71ab1dcc47c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DataSourceError",
          "evalue": "Unable to open /content/anugul_anugul.shx or /content/anugul_anugul.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0e9821ebc103>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load shapefiles using GeoPandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mvillages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvillage_shapefile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmicrowatersheds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicrowatershed_shapefile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pyogrio\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         return _read_file_pyogrio(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"include_fields\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyogrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyogrio/geopandas.py\u001b[0m in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# as numpy does not directly support timezones.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime_as_string\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     result = read_func(\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyogrio/raw.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdataset_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess_options_key_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     return ogr_read(\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mget_vsi_path_or_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpyogrio/_io.pyx\u001b[0m in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpyogrio/_io.pyx\u001b[0m in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDataSourceError\u001b[0m: Unable to open /content/anugul_anugul.shx or /content/anugul_anugul.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install BeautifulSoup\n",
        "!pip install requests\n",
        "!pip install base64\n",
        "!pip install Image\n",
        "!pip install openai\n",
        "!pip install pytesseract\n",
        "!pip install BytesIO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zjys1O6hS6zj",
        "outputId": "c86b0194-8390-4dae-aeda-272c6db13e39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting BeautifulSoup\n",
            "  Downloading BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement base64 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for base64\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting Image\n",
            "  Downloading image-1.5.33.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from Image) (11.0.0)\n",
            "Collecting django (from Image)\n",
            "  Downloading Django-5.1.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Image) (1.16.0)\n",
            "Collecting asgiref<4,>=3.8.1 (from django->Image)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django->Image) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.8.1->django->Image) (4.12.2)\n",
            "Downloading Django-5.1.4-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: Image\n",
            "  Building wheel for Image (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Image: filename=image-1.5.33-py2.py3-none-any.whl size=19482 sha256=e73ee7abc975b49d77abf4ae7c86fe763d27a8ec1f01fc4c20db2e0c5b999960\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/0c/a4/7cfa53a5c6225c2db2bfec08e782b43d0f25fdae2e995b69be\n",
            "Successfully built Image\n",
            "Installing collected packages: asgiref, django, Image\n",
            "Successfully installed Image-1.5.33 asgiref-3.8.1 django-5.1.4\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement BytesIO (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for BytesIO\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Y_atV_qtgkKT",
        "outputId": "93c15067-9ba7-4bad-dcbe-910b7ab34b8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "f044f0e762c342e1b73503a062394869"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import base64\n",
        "import openai\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def extract_html_content(file_path):\n",
        "    \"\"\"\n",
        "    Extracts text, images, and other data from an HTML file.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        soup = BeautifulSoup(file, \"html.parser\")\n",
        "\n",
        "    # Extract text content\n",
        "    text_content = soup.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "    # Extract images\n",
        "    images = []\n",
        "    for img_tag in soup.find_all(\"img\"):\n",
        "        img_src = img_tag.get(\"src\")\n",
        "        if img_src.startswith(\"data:image\"):  # Embedded base64 image\n",
        "            img_data = base64.b64decode(img_src.split(\",\")[1])\n",
        "            images.append(Image.open(BytesIO(img_data)))\n",
        "        elif img_src.startswith(\"http\"):  # External image URL\n",
        "            response = requests.get(img_src)\n",
        "            images.append(Image.open(BytesIO(response.content)))\n",
        "        else:\n",
        "            # Local image path relative to the HTML file\n",
        "            img_path = os.path.join(os.path.dirname(file_path), img_src)\n",
        "            if os.path.exists(img_path):\n",
        "                images.append(Image.open(img_path))\n",
        "\n",
        "    # Extract graphs and related metadata\n",
        "    graphs = [img for img in images if \"graph\" in img.format.lower()]  # Filter by metadata if available\n",
        "\n",
        "    return text_content, images, graphs\n",
        "\n",
        "\n",
        "def process_images(images):\n",
        "    \"\"\"\n",
        "    Extracts text from images using OCR.\n",
        "    \"\"\"\n",
        "    image_texts = []\n",
        "    for img in images:\n",
        "        try:\n",
        "            text = pytesseract.image_to_string(img)\n",
        "            image_texts.append(text.strip())\n",
        "        except Exception as e:\n",
        "            image_texts.append(f\"Error processing image: {str(e)}\")\n",
        "    return image_texts\n",
        "\n",
        "\n",
        "def prepare_context(text, image_texts):\n",
        "    \"\"\"\n",
        "    Combines textual data and extracted image text into a single context for the LLM.\n",
        "    \"\"\"\n",
        "    context = f\"Text Content:\\n{text}\\n\\n\"\n",
        "    for i, img_text in enumerate(image_texts):\n",
        "        context += f\"Image {i+1} Text:\\n{img_text}\\n\\n\"\n",
        "    return context\n",
        "\n",
        "\n",
        "def ask_question_to_llm(context, question):\n",
        "    \"\"\"\n",
        "    Sends the context and user question to the LLM and retrieves the answer.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert at analyzing and summarizing complex data from HTML files.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main(html_file_path, question):\n",
        "    text, images, graphs = extract_html_content(html_file_path)\n",
        "    image_texts = process_images(images)\n",
        "    context = prepare_context(text, image_texts)\n",
        "\n",
        "    # Limit context size to avoid hitting token limits\n",
        "    if len(context) > 100000:\n",
        "        context = context[:100000]\n",
        "\n",
        "    answer = ask_question_to_llm(context, question)\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Example usage\n",
        "html_file_path = \"/content/micro_watershed_report_pindwara.html\"\n",
        "question = \"What is the main takeaway from the data and images in the file?\"\n",
        "answer = main(html_file_path, question)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wuPI4I4e8sf",
        "outputId": "a6dbc1a1-2e2e-458c-e62c-c96db0182ef7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main takeaway from the Micro-Watershed Report focuses on the environmental challenges and agricultural practices in the Pindwara block, particularly highlighting the impact of drought on water resources and cropping intensity.\n",
            "\n",
            "Key points include:\n",
            "\n",
            "1. **Drought Impact**: The report emphasizes the significant effects of drought years (2021 and 2022) on surface water availability and cropping intensity. Surface water decreased notably during these years, affecting agricultural productivity.\n",
            "\n",
            "2. **Water Balance Issues**: There is a concerning trend of negative groundwater recharge, indicating over-extraction of groundwater resources despite the average annual rainfall being favorable in previous years.\n",
            "\n",
            "3. **Land Use Patterns**: The micro-watershed exhibits a predominance of farmland on plains, which could benefit from improved water conservation measures to enhance agricultural resilience.\n",
            "\n",
            "4. **Need for Conservation Measures**: Recommendations include adopting drought-resilient agricultural practices and implementing water harvesting structures to stabilize water availability and sustain productivity during dry spells.\n",
            "\n",
            "5. **NREGA Works**: The report mentions the importance of MGNREGA works aimed at soil and water conservation, indicating a proactive approach to counteract the adverse effects of drought and promote agricultural sustainability.\n",
            "\n",
            "Overall, the report underscores the urgent need for improved water management strategies in the face of climate variability and drought challenges to ensure the sustainability of agriculture in the region.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7a4jOzlKgeoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}